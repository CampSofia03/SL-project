#Decision Tree Regression

install.packages("rpart")
library(rpart)
install.packages("rpart.plot")

library(dplyr)

# Convert 'grade' to numeric
student <- student %>%
  mutate(grade_numeric = case_when(
    grade == "HighGrade" ~ 3,
    grade == "MediumGrade" ~ 2,
    grade == "LowGrade" ~ 1,
    grade == "Fail" ~ 0,
    TRUE ~ NA_real_  # Ensure missing values are treated as NA
  ))

# Build Decision Tree for Math Scores
dtm = rpart(formula = math.score ~ .,
           data = training_math,
           method = "anova");

# Build Decision Tree for Writing Scores - training_writing <- student[train, ]
dtw = rpart(formula = writing.score ~ .,
           data = training_writing,
           method = "anova");

par(mfrow = c(1,2))
prp(dtm, main = "Math Model")
prp(dtw, main = "Writing Model")
par(mfrow = c(1,1))

#Complexity parameter
printcp(dtm)
printcp(dtw)

#Training & Test Set
training_writing <- student[train, ]  # Training set (90% of data)
test <- setdiff(1:nrow(student), train)  # Get test indices
testing_writing <- student[test, ]  # Testing set (10% of data)
writing_predictions <- predict(dtw, newdata = testing_writing)

training_math <- student[train, ]  # Training set (90% of data)
test <- setdiff(1:nrow(student), train)  # Get test indices
testing_math <- student[test, ]  # Testing set (10% of data)
math_predictions <- predict(dtw, newdata = testing_writing)

# Predict on validation/test sets
#->testing_math <- testing_math[, !(names(testing_math) %in% c("Gender"))]
math_predictions <- as.numeric(math_predictions)
writing_predictions <- as.numeric(writing_predictions)
math_predictions <- predict(dtm, newdata = testing_math)
writing_predictions <- predict(dtw, newdata = testing_writing)

# Compute RMSE
math_rmse <- sqrt(mean((math_predictions - testing_math$math.score)^2))
writing_rmse <- sqrt(mean((writing_predictions - testing_writing$writing.score)^2))

cat("Math Model RMSE:", math_rmse, "\n")
cat("Writing Model RMSE:", writing_rmse, "\n")

#Standard deviation
math_sd <- sd(testing_math$math.score, na.rm = TRUE)
writing_sd <- sd(testing_writing$writing.score, na.rm = TRUE)

cat("Math Score Standard Deviation:", math_sd, "\n")
cat("Writing Score Standard Deviation:", writing_sd, "\n")

#riga 70????????
#Comparision with Linear Regression
lm_math <- lm(math.score ~ ., data = training_math)
lm_writing <- lm(writing.score ~ ., data = training_writing)

summary(lm_math)
summary(lm_writing)



prnm = rpart(formula = math.score ~ .,
             data = training_math,
             method = "anova", 
             control =rpart.control(minsplit = 5, cp=0.005));
prnw = rpart(formula = writing.score ~ .,
             data = training_writing,
             method = "anova", 
             control =rpart.control(minsplit = 5, cp=0.005));
ocpm = prnm$cptable[which.min(prnm$cptable[,"xerror"]), "CP"];
ocpw = prnw$cptable[which.min(prnw$cptable[,"xerror"]), "CP"];


#Variable importance
caret::varImp(dtw);
caret::varImp(dtm)

#Decision Tree Pruning

library(rpart)
library(rpart.plot)

# Train decision tree models
math_tree <- rpart(math.score ~ ., data = training_math, method = "anova", 
                   control = rpart.control(minsplit = 5, cp = 0.005))

writing_tree <- rpart(writing.score ~ ., data = training_writing, method = "anova", 
                      control = rpart.control(minsplit = 5, cp = 0.005))

# Find the optimal CP (complexity parameter) that minimizes cross-validation error
best_cp_math <- math_tree$cptable[which.min(math_tree$cptable[,"xerror"]), "CP"]
best_cp_writing <- writing_tree$cptable[which.min(writing_tree$cptable[,"xerror"]), "CP"]

# Prune the trees with the best CP found
math_tree_pruned <- prune(math_tree, cp = best_cp_math)
writing_tree_pruned <- prune(writing_tree, cp = best_cp_writing)

par(mfrow = c(1,2))  # Set up a 2-panel plot
prp(math_tree, main = "Math Model Before Pruning")  # Original tree
prp(math_tree_pruned, main = "Math Model After Pruning")  # Pruned tree
par(mfrow = c(1,1))  # Reset plotting layout

par(mfrow = c(1,2))  # Set up a 2-panel plot
prp(writing_tree, main = "Writing Model Before Pruning")  # Original tree
prp(writing_tree_pruned, main = "Writing Model After Pruning")  # Pruned tree
par(mfrow = c(1,1))  # Reset plotting layout

# Generate predictions on the test set using pruned models
math_pred <- predict(math_tree_pruned, newdata = testing_math)
writing_pred <- predict(writing_tree_pruned, newdata = testing_writing)

#RMSE
math_rmse <- sqrt(mean((math_pred - testing_math$math.score)^2))
writing_rmse <- sqrt(mean((writing_pred - testing_writing$writing.score)^2))

cat("Math Model RMSE After Pruning:", math_rmse, "\n")
cat("Writing Model RMSE After Pruning:", writing_rmse, "\n")

caret::varImp(math_tree_pruned);
caret::varImp(writing_tree_pruned)
